# -*- coding: utf-8 -*-
"""MSPA4_Final5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yBD0DsdLaMp7481bnuog1NQh5irwbqxw

Uploading CSV Files
"""

# from google.colab import files
# files.upload()

"""Package Importing"""

from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.model_selection import KFold, cross_val_score
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import r2_score,mean_squared_error

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from prophet import Prophet
import plotly.express as px

# !pip install prophet

data =pd.read_csv('/content/AAPL.csv')

"""#EDA"""

data.info()

data.describe()

data=data.drop("Adj Close",axis='columns')

data.index = pd.DatetimeIndex(data['Date'])

data.head()

data.info()

plt.figure(figsize=(30,8))
sns.set_style('darkgrid')
sns.lineplot(y='Close',x=data.index,data=data)
plt.show()

"""Selecting Feature & Label"""

X = data.drop('Close', axis='columns')
y = data['Close']

X.shape,y.shape

#Check for missing values
X.isnull().sum()
# No missing values , so no need of imputation on dataset is required

X = X.drop('Date',axis='columns')

X.head()

closedf = data[['Date','Close']]
print("Shape of close dataframe:", data.shape)

fig = px.line(closedf, x=closedf.Date, y=closedf.Close,labels={'Date':'Date','Close':'Close Stock'})
fig.update_traces(marker_line_width=2, opacity=0.8)
fig.update_layout(title_text='Stock close price chart', plot_bgcolor='white', font_size=15, font_color='black')
fig.update_xaxes(showgrid=False)
fig.update_yaxes(showgrid=False)
fig.show()

"""Data splitting with ratio of train:test as 80:20


"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4)

"""#Defining of preprocessing funtion

#Feature Scaling

---
"""

scaler = MinMaxScaler()
num = ['Open','High','Low','Volume']

X_train[num]= scaler.fit_transform(X_train[num])
X_test[num]= scaler.fit_transform(X_test[num])

"""#Model Selection : Deciding of optimal parameters 



"""

mlp = MLPRegressor(warm_start=True,random_state=48, solver  = 'adam',
    hidden_layer_sizes= (75,100,120),
    activation ='relu',
    alpha = 0.0001,
    learning_rate = 'adaptive',
    max_iter = 1200,
    early_stopping=True)

# grid_param = {validation_fraction
#     'solver' : ['adam','lbfgs','sgd'],
#     'hidden_layer_sizes': [(250,200,150)],
#     'activation':['relu','logistic','tanh'],
#     'alpha': [
#         0.0001, 0.001],
#     'learning_rate': ['adaptive','invscaling', 'constant'],
#     'max_iter' : [15000]
# }

"""#Model Fitting and Validation Scoring"""

# grid_search = GridSearchCV(mlp, grid_param, cv = 3, n_jobs = -1)
# grid_search.fit(X_train, y_train)
# best_model = grid_search.best_estimator_

best_model = mlp.fit(X_train, y_train,)
kfold = KFold(n_splits=5)
val_score = cross_val_score(best_model,X_train,y_train,cv=kfold)

print("Validation Score of given Model is : ", val_score)

from sklearn.metrics import r2_score

y_pred = best_model.predict(X_test)
print('R2 score of Model is ',r2_score(y_test, y_pred))

# Train the model and record the training and validation losses for each epoch
train_losses = []
val_losses = []
for i in range(mlp.max_iter):
    mlp.fit(X_train, y_train)
    train_losses.append(mlp.loss_)



val_losses = mlp.validation_scores_


# Plot the training and validation losses vs epochs
epochs = np.arange(1, mlp.max_iter+1)
plt.figure(figsize=(25,10))
# plt.ylim(0.1, 1)
# plt.yticks(np.arange(0.24, 1.1, 0.01))
# plt.plot(range(len(val_losses)), val_losses,label='Validation Loss')
plt.plot(epochs, train_losses,label='Training Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

plt.figure(figsize=(22,10))
plt.plot(range(len(val_losses)), val_losses,label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.3)

train_errors, val_errors = [], []
for i in range(mlp.max_iter):
    mlp.fit(X_train, y_train)
    y_train_pred = mlp.predict(X_train)
    y_val_pred = mlp.predict(X_valid)
    train_errors.append(mean_squared_error(y_train, y_train_pred))
    val_errors.append(mean_squared_error(y_valid, y_val_pred))

# plot the training and validation errors
plt.figure(figsize=(20,8))
epochs = np.arange(1, mlp.max_iter+1)
plt.plot(epochs, train_errors, label='Training MSE')
plt.plot(epochs, val_errors, label='Validation MSE')
plt.title('Training and Validation MSE vs Epochs')
plt.xlabel('Epochs')
plt.ylabel('MSE')
plt.legend()
plt.show()

# Get the weights of the model

print("Weights feeded to First Hidden layer are :", mlp.coefs_[0])

print("Weights feeded to Second Hidden layer are :", mlp.coefs_[1])

print("Weights feeded to Third Hidden layer are :", mlp.coefs_[2])

fig,ax =plt.subplots(figsize=(26,10))
sns.set_style('darkgrid')
sns.lineplot( data=y_test,ax=ax,label='Actual Close Price',color='Red')
sns.lineplot( y =y_pred, x=y_test.index, ax=ax,label='Predict Close Price',color='LightGreen')

"""#Prophet Model for Future Change in Stock Price"""

future_pred_price = pd.DataFrame(columns=['ds', 'y'])
future_pred_price['ds']= data['Date']
future_pred_price['y'] = data['Close']

future_pred_model = Prophet()
future_pred_model.fit(future_pred_price)

future_dates = future_pred_model.make_future_dataframe(periods=365)
forecast = future_pred_model.predict(future_dates)

plt.figure(figsize=(25,20))
future_pred_model.plot(forecast)
plt.title("Forecasts from the Prophet model for Change in Stock Price")

plt.xlabel('Date')
plt.ylabel('Stock Closing Price')

plt.show()